# -*- coding: utf-8 -*-
"""ECG.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qyhjhjcAa9q87zXtEfUT6VcMDvs_1KAB

## Imports
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install google-cloud-storage==1.41.1
# !pip install -qqq wandb pytorch-lightning
# 
import io
import PIL.Image as Image
import ast
import os
import torch
import torchvision
import numpy as np
from torch import nn
import torch.nn.functional as F
import pytorch_lightning as pl
from pytorch_lightning.callbacks import Callback
from pytorch_lightning.callbacks.early_stopping import EarlyStopping
from pytorch_lightning.metrics.functional import accuracy
from pytorch_lightning.loggers import WandbLogger
from pytorch_lightning.callbacks import ModelCheckpoint
import wandb
# from google.cloud import storage
import pickle
from torchvision import transforms
from torch.utils.data import DataLoader, random_split, Dataset

# setting device on GPU if available, else CPU
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print('Using device:', device)
print()

"""## Data"""

# Setting credentials using the downloaded JSON file
path = 'model-azimuth-321409-241148a4b144.json'
if not os.path.isfile(path):
    raise ("Please provide the gcs key in the root directory")
# client = storage.Client.from_service_account_json(json_credentials_path=path)
client = storage.Client.from_service_account_json(json_credentials_path='/content/model-azimuth-321409-241148a4b144.json')
bucket = client.get_bucket('ecg-arrhythmia-classification')

# from torchvision.datasets.cifar import CIFAR10

class PtbData(Dataset):

    def __init__(self, data_map_url, data_url, gender, under_50, is_train, download=False, transform=None):
        """
        Args:
        
        """

        self.data_url = data_url
        self.gender = gender
        self.under_50 = under_50
        self.transform = transform
        self.state = 'train' if is_train else 'test'

        if download:
            blob_obj = bucket.blob(data_map_url)
            self.data_map = ast.literal_eval(blob_obj.download_as_string().decode('utf-8')) 
            # assert(False)
            self.data_map[self.state][self.gender][self.under_50]['A'] +=\
               self.data_map[self.state][self.gender][self.under_50]['B']
            
            self.data_map[self.state][self.gender][self.under_50]['Y_A'] +=\
               self.data_map[self.state][self.gender][self.under_50]['Y_B']
               
            with open('data_map.pickle', 'wb') as handle:
                pickle.dump(self.data_map, handle, protocol=pickle.HIGHEST_PROTOCOL)
        else:
            with open('data_map.pickle', 'rb') as handle:
                self.data_map = pickle.load(handle)

    def __len__(self):
        # print('state: ', self.state, '. gender: ', self.gender, '. under 50: ', self.under_50, '. A')
        return len(self.data_map[self.state][self.gender][self.under_50]['A']) # +\
        # len(self.data_map[self.state][self.gender][self.under_50]['B'])

    def __getitem__(self, idx):
        blob_obj = bucket.blob("{}".format(self.data_map[self.state][self.gender][self.under_50]['A'][idx]))
        # sample = pickle.loads(blob_obj.download_as_bytes())
        sample = Image.open(io.BytesIO(blob_obj.download_as_bytes())).convert('L')
        y = self.data_map[self.state][self.gender][self.under_50]['Y_A'][idx]
        if self.transform:
            sample = self.transform(sample)
        return sample, y


class DataModule(pl.LightningDataModule):
    def __init__(self, batch_size, data_map_url, data_url, gender, under_50, is_train, transform=None):
        super().__init__()
        self.batch_size = batch_size

        self.data_map_url = data_map_url
        self.data_url = data_url
        self.gender = 0 if gender == "male" else 1
        self.under_50 = '<' if under_50 else '>='
        self.state = 'train' if is_train else 'test'
        
        self.transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.5), (0.5))
            # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
        ])


    def prepare_data(self):
        # download
        PtbData(self.data_map_url, self.data_url, self.gender, self.under_50, self.state, download=True, transform=self.transform)
  

    def setup(self, stage=None):
        # Assign train/val datasets for use in dataloaders
        if stage == 'train' or stage is None:
            ptb_full = PtbData(self.data_map_url, self.data_url, self.gender, self.under_50, 'train', transform=self.transform)
            self.train, self.val = random_split(ptb_full, [round(len(ptb_full)*0.8), len(ptb_full) - round(len(ptb_full)*0.8)])
            print('len ptb_full: ', len(ptb_full))
            print('len train: ', len(self.train))
            print('len val: ', len(self.val))

        # Assign test dataset for use in dataloader(s)
        if stage == 'test' or stage is None:
            self.test = PtbData(self.data_map_url, self.data_url, self.gender, self.under_50, 'test', transform=self.transform)
            print('len test: ', len(self.test))

    def train_dataloader(self):
        return DataLoader(self.train, batch_size=self.batch_size, shuffle=True)

    def val_dataloader(self):
        return DataLoader(self.val, batch_size=self.batch_size)

    def test_dataloader(self):
        return DataLoader(self.test, batch_size=self.batch_size)

"""## Model"""

class PaperNet(pl.LightningModule):
    def __init__(self, input_shape, num_classes, device, learning_rate=2e-4):
        super().__init__()

        # log hyperparameters
        self.save_hyperparameters()
        self.learning_rate = learning_rate

        self.features = nn.Sequential(
            nn.Conv2d(1, 8, 4),
            nn.BatchNorm2d(8),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(8, 13, 2),
            nn.BatchNorm2d(13),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(13, 13, 2),
            nn.BatchNorm2d(13),
            nn.ReLU(),
            nn.MaxPool2d(2)
        ).to(device)

        self.features_num = self._get_conv_output(input_shape)

        self.classifier = nn.Sequential(
            nn.Linear(self.features_num, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),
            nn.Linear(512, num_classes),
            nn.Softmax(-1)
        ).to(device)

    # returns the size of the output tensor going into Linear layer from the conv block.
    def _get_conv_output(self, shape):
        batch_size = 1
        input = torch.autograd.Variable(torch.rand(batch_size, *shape)).cuda()

        output_feat = self.features(input)
        n_size = output_feat.data.view(batch_size, -1).size(1)
        return n_size

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.classifier(x)
        return x

    def training_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)

        # training metrics
        preds = torch.argmax(logits, dim=1)
        acc = accuracy(preds, y)
        self.log('train_loss', loss, on_step=True, on_epoch=True, logger=True)
        self.log('train_acc', acc, on_step=True, on_epoch=True, logger=True)

        return loss #{'loss': loss}

    def validation_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        
        loss = F.nll_loss(logits, y)
        # validation metrics
        preds = torch.argmax(logits, dim=1)
        acc = accuracy(preds, y)
        self.log('val_loss', loss, prog_bar=True)
        self.log('val_acc', acc, prog_bar=True)
        return loss #{'loss': loss}

    def test_step(self, batch, batch_idx):
        x, y = batch
        logits = self(x)
        loss = F.nll_loss(logits, y)

        # validation metrics
        preds = torch.argmax(logits, dim=1)
        acc = accuracy(preds, y)
        self.log('test_loss', loss, prog_bar=True)
        self.log('test_acc', acc, prog_bar=True)
        return loss #{'loss': loss}

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)
        return optimizer


class ImagePredictionLogger(Callback):
    def __init__(self, val_samples, classes_names, num_samples=10):
        super().__init__()
        self.num_samples = num_samples
        self.val_imgs, self.val_labels = val_samples
        self.classes_names = classes_names

    def on_validation_epoch_end(self, trainer, pl_module):
        # Bring the tensors to CPU
        val_imgs = self.val_imgs.to(device=pl_module.device)
        val_labels = self.classes_names[self.val_labels]#.to(device=pl_module.device)
        # Get model prediction
        logits = pl_module(val_imgs)
        preds = self.classes_names[torch.argmax(logits, -1).cpu()]
        # Log the images as wandb Image
        trainer.logger.experiment.log({
            "examples": [wandb.Image(x, caption=f"Pred:{pred}, Label:{y}")
                         for x, pred, y in zip(val_imgs[:self.num_samples],
                                               preds[:self.num_samples],
                                               val_labels[:self.num_samples])]
        })

"""## Training"""

# from .nets import PaperNet, WandbLogger, pl, ImagePredictionLogger
# from .data_modules import CIFAR10DataModule
# from pytorch_lightning.callbacks.early_stopping import EarlyStopping
# from pytorch_lightning.callbacks import ModelCheckpoint

# Init our data pipeline
data_map_url = "data_map"
data_url = "STFT"
gender = "male"
under_50 = True
is_train = True
batch_size = 32
input_shape = (1, 256, 256)

super_classes = np.array(["CD", "HYP", "MI", "NORM", "STTC"])
dm = DataModule(batch_size, data_map_url, data_url, gender, under_50, is_train)
dm.prepare_data()
dm.setup()

# %debug

# Samples required by the custom ImagePredictionLogger callback to log image predictions.
val_samples = next(iter(dm.val_dataloader()))
val_imgs, val_labels = val_samples[0], val_samples[1]
val_imgs.shape, val_labels.shape

# Init our model
model = PaperNet(input_shape, len(super_classes), device)

# Initialize wandb logger
wandb_logger = WandbLogger(project='ECG_spec_classify', job_type='train')


early_stop_callback = EarlyStopping(
   monitor='val_loss',
   patience=3,
   verbose=False,
   mode='min'
)

MODEL_CKPT_PATH = 'model/'
MODEL_CKPT = 'model/model-{epoch:02d}-{val_loss:.2f}'

checkpoint_callback = ModelCheckpoint(
    monitor='val_loss',
    filename=MODEL_CKPT,
    save_top_k=3,
    mode='min')

# Initialize a trainer
# trainer = pl.Trainer(max_epochs=2,
#                      progress_bar_refresh_rate=20,
#                      gpus=1,
#                      logger=wandb_logger,
#                      callbacks=[early_stop_callback,
#                                 ImagePredictionLogger(val_samples)],
#                      checkpoint_callback=checkpoint_callback)

trainer = pl.Trainer(
    logger=wandb_logger,    # W&B integration
    log_every_n_steps=10,   # set the logging frequency
    gpus=-1,                # use all GPUs
    max_epochs=1,           # number of epochs
    deterministic=True,     # keep it deterministic
    callbacks=[ImagePredictionLogger(val_samples, super_classes)] # see Callbacks section
    )

# Train the model âš¡ðŸš…âš¡
trainer.fit(model, datamodule=dm)

# evaluate the model on a test set
trainer.test(model)  # uses last-saved model


# Close wandb run
wandb.finish()

import matplotlib.pyplot as plt
plt.imshow(val_imgs[3][0])

model.features_num